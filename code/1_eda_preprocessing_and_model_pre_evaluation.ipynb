{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, recall_score, precision_score, f1_score, classification_report, RocCurveDisplay, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_deck = pd.read_json('../data/steam_deck_reddit_posts_1.json')\n",
    "df_steam_deck_2 = pd.read_json('../data/steam_deck_reddit_posts_2.json')\n",
    "df_steam_deck_flair = pd.read_json('../data/steam_deck_reddit_posts_flair_1.json')\n",
    "df_steam_deck_flair_2 = pd.read_json('../data/steam_deck_reddit_posts_flair_2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract label to the new column 'tag'\n",
    "def extract_flair(x):\n",
    "    if len(x) == 1:\n",
    "        return x[0]['t']\n",
    "    elif len(x) == 2:\n",
    "        return x[1]['t']\n",
    "    else:\n",
    "        return 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Picture\n",
       "1       Picture\n",
       "2       Picture\n",
       "3    Discussion\n",
       "4         Video\n",
       "Name: tag, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract flair to tag\n",
    "df_steam_deck['tag'] = df_steam_deck['link_flair_richtext'].map(extract_flair)\n",
    "df_steam_deck['tag'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Meme / Shitpost\n",
       "1         Hot Wasabi\n",
       "2         Discussion\n",
       "3            Picture\n",
       "4            Picture\n",
       "Name: tag, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_steam_deck_2['tag'] = df_steam_deck_2['link_flair_richtext'].map(extract_flair)\n",
    "df_steam_deck_2['tag'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Size comparison</td>\n",
       "      <td>My legion go just came in today and dang this ...</td>\n",
       "      <td>Picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traveling for work and the game wasn't on TV.</td>\n",
       "      <td>I mean, it's a PC right.</td>\n",
       "      <td>Picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I know they're not the highest in performance,...</td>\n",
       "      <td></td>\n",
       "      <td>Picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just a warning for winter: The Steam’s Deck ba...</td>\n",
       "      <td>It was probably 35° outside(so figure around 5...</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you're not playing COCOON on the Deck, you'...</td>\n",
       "      <td></td>\n",
       "      <td>Video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12699</th>\n",
       "      <td>Sure buddy, it's all ok</td>\n",
       "      <td></td>\n",
       "      <td>Meta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12700</th>\n",
       "      <td>Good soldiers follow orders</td>\n",
       "      <td></td>\n",
       "      <td>Meta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12701</th>\n",
       "      <td>Barely any of them are unpopular</td>\n",
       "      <td></td>\n",
       "      <td>Meta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12702</th>\n",
       "      <td>OG Fantasy Writer</td>\n",
       "      <td></td>\n",
       "      <td>Meta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12703</th>\n",
       "      <td>My Pillow CEO who ranted about election conspi...</td>\n",
       "      <td></td>\n",
       "      <td>Meta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12704 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                        Size comparison   \n",
       "1          Traveling for work and the game wasn't on TV.   \n",
       "2      I know they're not the highest in performance,...   \n",
       "3      Just a warning for winter: The Steam’s Deck ba...   \n",
       "4      If you're not playing COCOON on the Deck, you'...   \n",
       "...                                                  ...   \n",
       "12699                            Sure buddy, it's all ok   \n",
       "12700                        Good soldiers follow orders   \n",
       "12701                   Barely any of them are unpopular   \n",
       "12702                                  OG Fantasy Writer   \n",
       "12703  My Pillow CEO who ranted about election conspi...   \n",
       "\n",
       "                                                selftext         tag  \n",
       "0      My legion go just came in today and dang this ...     Picture  \n",
       "1                               I mean, it's a PC right.     Picture  \n",
       "2                                                            Picture  \n",
       "3      It was probably 35° outside(so figure around 5...  Discussion  \n",
       "4                                                              Video  \n",
       "...                                                  ...         ...  \n",
       "12699                                                           Meta  \n",
       "12700                                                           Meta  \n",
       "12701                                                           Meta  \n",
       "12702                                                           Meta  \n",
       "12703                                                           Meta  \n",
       "\n",
       "[12704 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine into 1 df\n",
    "combined_df = pd.concat([\n",
    "        df_steam_deck[['title', 'selftext', 'tag']],\n",
    "        df_steam_deck_2[['title', 'selftext', 'tag']],\n",
    "        df_steam_deck_flair[['title', 'selftext', 'tag']],\n",
    "        df_steam_deck_flair_2[['title', 'selftext', 'tag']]\n",
    "    ], axis=0).reset_index(drop=True)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12704, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Size comparison</td>\n",
       "      <td>My legion go just came in today and dang this ...</td>\n",
       "      <td>Picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traveling for work and the game wasn't on TV.</td>\n",
       "      <td>I mean, it's a PC right.</td>\n",
       "      <td>Picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I know they're not the highest in performance,...</td>\n",
       "      <td></td>\n",
       "      <td>Picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just a warning for winter: The Steam’s Deck ba...</td>\n",
       "      <td>It was probably 35° outside(so figure around 5...</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you're not playing COCOON on the Deck, you'...</td>\n",
       "      <td></td>\n",
       "      <td>Video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                    Size comparison   \n",
       "1      Traveling for work and the game wasn't on TV.   \n",
       "2  I know they're not the highest in performance,...   \n",
       "3  Just a warning for winter: The Steam’s Deck ba...   \n",
       "4  If you're not playing COCOON on the Deck, you'...   \n",
       "\n",
       "                                            selftext         tag  \n",
       "0  My legion go just came in today and dang this ...     Picture  \n",
       "1                           I mean, it's a PC right.     Picture  \n",
       "2                                                        Picture  \n",
       "3  It was probably 35° outside(so figure around 5...  Discussion  \n",
       "4                                                          Video  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title       0\n",
       "selftext    0\n",
       "tag         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12704, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check remaining data\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3657, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check duplicate posts\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Size comparison</td>\n",
       "      <td>My legion go just came in today and dang this ...</td>\n",
       "      <td>Picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traveling for work and the game wasn't on TV.</td>\n",
       "      <td>I mean, it's a PC right.</td>\n",
       "      <td>Picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I know they're not the highest in performance,...</td>\n",
       "      <td></td>\n",
       "      <td>Picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just a warning for winter: The Steam’s Deck ba...</td>\n",
       "      <td>It was probably 35° outside(so figure around 5...</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you're not playing COCOON on the Deck, you'...</td>\n",
       "      <td></td>\n",
       "      <td>Video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                    Size comparison   \n",
       "1      Traveling for work and the game wasn't on TV.   \n",
       "2  I know they're not the highest in performance,...   \n",
       "3  Just a warning for winter: The Steam’s Deck ba...   \n",
       "4  If you're not playing COCOON on the Deck, you'...   \n",
       "\n",
       "                                            selftext         tag  \n",
       "0  My legion go just came in today and dang this ...     Picture  \n",
       "1                           I mean, it's a PC right.     Picture  \n",
       "2                                                        Picture  \n",
       "3  It was probably 35° outside(so figure around 5...  Discussion  \n",
       "4                                                          Video  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "Question           635\n",
       "Tech Support       401\n",
       "Picture            304\n",
       "Video              290\n",
       "Meme / Shitpost    260\n",
       "News               259\n",
       "Guide              253\n",
       "MEGATHREAD         251\n",
       "Configuration      249\n",
       "Meta               243\n",
       "Feature Request    233\n",
       "Discussion         175\n",
       "Hot Wasabi         104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check label distribution\n",
    "combined_df['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1649\n"
     ]
    }
   ],
   "source": [
    "# Check empty text\n",
    "print(combined_df[combined_df['tag'] == '']['tag'].count())\n",
    "print(combined_df[combined_df['title'] == '']['title'].count())\n",
    "print(combined_df[combined_df['selftext'] == '']['selftext'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined text from title, selftext (unused)\n",
    "combined_df['all_text'] = combined_df['title'] + ' ' + combined_df['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>tag</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Size comparison</td>\n",
       "      <td>My legion go just came in today and dang this ...</td>\n",
       "      <td>Picture</td>\n",
       "      <td>Size comparison My legion go just came in toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traveling for work and the game wasn't on TV.</td>\n",
       "      <td>I mean, it's a PC right.</td>\n",
       "      <td>Picture</td>\n",
       "      <td>Traveling for work and the game wasn't on TV. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I know they're not the highest in performance,...</td>\n",
       "      <td></td>\n",
       "      <td>Picture</td>\n",
       "      <td>I know they're not the highest in performance,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just a warning for winter: The Steam’s Deck ba...</td>\n",
       "      <td>It was probably 35° outside(so figure around 5...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Just a warning for winter: The Steam’s Deck ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you're not playing COCOON on the Deck, you'...</td>\n",
       "      <td></td>\n",
       "      <td>Video</td>\n",
       "      <td>If you're not playing COCOON on the Deck, you'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                    Size comparison   \n",
       "1      Traveling for work and the game wasn't on TV.   \n",
       "2  I know they're not the highest in performance,...   \n",
       "3  Just a warning for winter: The Steam’s Deck ba...   \n",
       "4  If you're not playing COCOON on the Deck, you'...   \n",
       "\n",
       "                                            selftext         tag  \\\n",
       "0  My legion go just came in today and dang this ...     Picture   \n",
       "1                           I mean, it's a PC right.     Picture   \n",
       "2                                                        Picture   \n",
       "3  It was probably 35° outside(so figure around 5...  Discussion   \n",
       "4                                                          Video   \n",
       "\n",
       "                                            all_text  \n",
       "0  Size comparison My legion go just came in toda...  \n",
       "1  Traveling for work and the game wasn't on TV. ...  \n",
       "2  I know they're not the highest in performance,...  \n",
       "3  Just a warning for winter: The Steam’s Deck ba...  \n",
       "4  If you're not playing COCOON on the Deck, you'...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records with empty selftext or title\n",
    "# combined_df = combined_df.loc[(combined_df['title'] != '') & (combined_df['selftext'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After error analysis, try to combine some tag together\n",
    "# combined_df['tag'] = combined_df['tag'].map(lambda x: 'QA/Tech Support' if x in ['Question', 'Tech Support'] else x)\n",
    "# combined_df['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: Pre-Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = combined_df[['selftext', 'title']]\n",
    "y = combined_df['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My legion go just came in today and dang this ...</td>\n",
       "      <td>Size comparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I mean, it's a PC right.</td>\n",
       "      <td>Traveling for work and the game wasn't on TV.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>I know they're not the highest in performance,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was probably 35° outside(so figure around 5...</td>\n",
       "      <td>Just a warning for winter: The Steam’s Deck ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>If you're not playing COCOON on the Deck, you'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext  \\\n",
       "0  My legion go just came in today and dang this ...   \n",
       "1                           I mean, it's a PC right.   \n",
       "2                                                      \n",
       "3  It was probably 35° outside(so figure around 5...   \n",
       "4                                                      \n",
       "\n",
       "                                               title  \n",
       "0                                    Size comparison  \n",
       "1      Traveling for work and the game wasn't on TV.  \n",
       "2  I know they're not the highest in performance,...  \n",
       "3  Just a warning for winter: The Steam’s Deck ba...  \n",
       "4  If you're not playing COCOON on the Deck, you'...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "Question           0.173640\n",
       "Tech Support       0.109653\n",
       "Picture            0.083128\n",
       "Video              0.079300\n",
       "Meme / Shitpost    0.071097\n",
       "News               0.070823\n",
       "Guide              0.069182\n",
       "MEGATHREAD         0.068635\n",
       "Configuration      0.068089\n",
       "Meta               0.066448\n",
       "Feature Request    0.063713\n",
       "Discussion         0.047853\n",
       "Hot Wasabi         0.028439\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline acc.\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set custom stopwords for removing some of the words that are too specific\n",
    "custom_stop_words = ['steam', 'deck', 'steamdeck'] + [tag.lower() for tag in combined_df['tag'].unique()] # subreddit keyword and tag name\n",
    "english_stop_words = list(CountVectorizer(stop_words='english').get_stop_words())\n",
    "all_stop_words = custom_stop_words + english_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare vectorizer\n",
    "vectorizer_list = {\n",
    "    'CVEC_Eng_Stop': CountVectorizer(stop_words='english'),\n",
    "    'TVEC_Eng_Stop': TfidfVectorizer(stop_words='english'),\n",
    "    'CVEC_Custom_Stop': CountVectorizer(stop_words=all_stop_words),\n",
    "    'TVEC_Custom_Stop': TfidfVectorizer(stop_words=all_stop_words)\n",
    "}\n",
    "\n",
    "X_vec_list = {}\n",
    "\n",
    "for name, vectorizer in vectorizer_list.items():\n",
    "    X_vec = ColumnTransformer([\n",
    "            ('selftext_vec', vectorizer, 'selftext'),\n",
    "            ('title_vec', vectorizer, 'title')\n",
    "        ],\n",
    "        remainder='drop',\n",
    "        n_jobs=-1\n",
    "    ).fit_transform(X)\n",
    "\n",
    "    X_vec_list[name] = X_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-evaluate models for further selection + optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for generating scores to pre-evaluate models for further selection + optimization\n",
    "def pre_evaluate_models(est):\n",
    "    result_df_classif = pd.DataFrame()\n",
    "\n",
    "    for vec_name, X_vec in X_vec_list.items():\n",
    "        # Train-Test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_vec, y, random_state=42, stratify=y)\n",
    "\n",
    "        row_name = vec_name + ' ' + str(est)\n",
    "        # Train\n",
    "        print('Training', row_name, '...')\n",
    "        est.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = est.predict(X_train)\n",
    "        y_test_pred = est.predict(X_test)\n",
    "\n",
    "        # Scoring\n",
    "        print('Scoring', row_name, '...\\n')\n",
    "        \n",
    "        result_df_classif.loc[row_name, 'cv_train'] = cross_val_score(est, X_train, y_train, cv=5).mean()\n",
    "        result_df_classif.loc[row_name, 'cv_test'] = cross_val_score(est, X_test, y_test, cv=5).mean()\n",
    "        result_df_classif.loc[row_name, 'accuracy_train'] = est.score(X_train, y_train)\n",
    "        result_df_classif.loc[row_name, 'accuracy_test'] = est.score(X_test, y_test)\n",
    "        result_df_classif.loc[row_name, 'f1_train'] = f1_score(y_train, y_train_pred, average='micro')\n",
    "        result_df_classif.loc[row_name, 'f1_test'] = f1_score(y_test, y_test_pred, average='micro')\n",
    "    \n",
    "    return result_df_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop pre-evaluation on various estimators, put results in dataframe\n",
    "# estimator_list = [\n",
    "#     LogisticRegression(n_jobs=-1),\n",
    "#     MultinomialNB(),\n",
    "#     # DecisionTreeClassifier(),\n",
    "#     # BaggingClassifier(n_jobs=-1),\n",
    "#     RandomForestClassifier(min_samples_leaf=5, n_jobs=-1),\n",
    "#     AdaBoostClassifier()\n",
    "# ]\n",
    "\n",
    "# pre_evaluation_result = pd.DataFrame()\n",
    "# for estimator in estimator_list:\n",
    "#     pre_evaluation_result = pd.concat([pre_evaluation_result, pre_evaluate_models(estimator)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_evaluation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of previous code blocks (skipped because of long runtime)\n",
    "\n",
    "![Pre Evaluation Result](../image/pre_evaluation_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "Question           0.173640\n",
       "Tech Support       0.109653\n",
       "Picture            0.083128\n",
       "Video              0.079300\n",
       "Meme / Shitpost    0.071097\n",
       "News               0.070823\n",
       "Guide              0.069182\n",
       "MEGATHREAD         0.068635\n",
       "Configuration      0.068089\n",
       "Meta               0.066448\n",
       "Feature Request    0.063713\n",
       "Discussion         0.047853\n",
       "Hot Wasabi         0.028439\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline for model comparison\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare vectorized data for selected model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom tokenizer, to do tokenize + lemmatize\n",
    "import spacy\n",
    "\n",
    "def tokenize_lemmatize(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_punct and not token.is_stop and token.is_alpha]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cvec_lemmatized.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizing + Lemmatize\n",
    "# ct_vectorizer = ColumnTransformer([\n",
    "#                 ('selftext_vec', CountVectorizer(tokenizer=tokenize_lemmatize), 'selftext'),\n",
    "#                 ('title_vec', CountVectorizer(tokenizer=tokenize_lemmatize), 'title')\n",
    "#             ],\n",
    "#             remainder='drop',\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "\n",
    "# X_cvec = ct_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# cvec_lemmatized_df = pd.concat([pd.DataFrame(X_cvec.toarray(), columns=ct_vectorizer.get_feature_names_out()), y], axis=1)\n",
    "# cvec_lemmatized_df.to_csv('../data/cvec_lemmatized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvec_lemmatized.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizing + Lemmatize\n",
    "# ct_vectorizer = ColumnTransformer([\n",
    "#                 ('selftext_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize), 'selftext'),\n",
    "#                 ('title_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize), 'title')\n",
    "#             ],\n",
    "#             remainder='drop',\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "\n",
    "# X_tvec = ct_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# tvec_lemmatized_df = pd.concat([pd.DataFrame(X_tvec.toarray(), columns=ct_vectorizer.get_feature_names_out()), y], axis=1)\n",
    "# tvec_lemmatized_df.to_csv('../data/tvec_lemmatized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvec_lemmatized_150.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizing + Lemmatize\n",
    "# ct_vectorizer = ColumnTransformer([\n",
    "#                 ('selftext_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=150), 'selftext'),\n",
    "#                 ('title_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=150), 'title')\n",
    "#             ],\n",
    "#             remainder='drop',\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "\n",
    "# X_tvec = ct_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# tvec_lemmatized_df = pd.concat([pd.DataFrame(X_tvec.toarray(), columns=ct_vectorizer.get_feature_names_out()), y], axis=1)\n",
    "# tvec_lemmatized_df.to_csv('../data/tvec_lemmatized_150.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvec_lemmatized_250_max_df_0.2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizing + Lemmatize\n",
    "# ct_vectorizer = ColumnTransformer([\n",
    "#                 ('selftext_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=250, max_df=0.2), 'selftext'),\n",
    "#                 ('title_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=250, max_df=0.2), 'title')\n",
    "#             ],\n",
    "#             remainder='drop',\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "\n",
    "# X_tvec = ct_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# tvec_lemmatized_df = pd.concat([pd.DataFrame(X_tvec.toarray(), columns=ct_vectorizer.get_feature_names_out()), y], axis=1)\n",
    "# tvec_lemmatized_df.to_csv('../data/tvec_lemmatized_250_max_df_0.2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvec_lemmatized_500_max_df_0.2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizing + Lemmatize\n",
    "# ct_vectorizer = ColumnTransformer([\n",
    "#                 ('selftext_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=500, max_df=0.2), 'selftext'),\n",
    "#                 ('title_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=500, max_df=0.2), 'title')\n",
    "#             ],\n",
    "#             remainder='drop',\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "\n",
    "# X_tvec = ct_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# tvec_lemmatized_df = pd.concat([pd.DataFrame(X_tvec.toarray(), columns=ct_vectorizer.get_feature_names_out()), y], axis=1)\n",
    "# tvec_lemmatized_df.to_csv('../data/tvec_lemmatized_500_max_df_0.2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvec_lemmatized_1000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizing + Lemmatize\n",
    "ct_vectorizer = ColumnTransformer([\n",
    "                ('selftext_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=1000), 'selftext'),\n",
    "                ('title_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=1000), 'title')\n",
    "            ],\n",
    "            remainder='drop',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "X_tvec = ct_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "tvec_lemmatized_df = pd.concat([pd.DataFrame(X_tvec.toarray(), columns=ct_vectorizer.get_feature_names_out()), y], axis=1)\n",
    "tvec_lemmatized_df.to_csv('../data/tvec_lemmatized_1000.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvec_lemmatized_1500.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizing + Lemmatize\n",
    "# ct_vectorizer = ColumnTransformer([\n",
    "#                 ('selftext_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=1500), 'selftext'),\n",
    "#                 ('title_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=1500), 'title')\n",
    "#             ],\n",
    "#             remainder='drop',\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "\n",
    "# X_tvec = ct_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# tvec_lemmatized_df = pd.concat([pd.DataFrame(X_tvec.toarray(), columns=ct_vectorizer.get_feature_names_out()), y], axis=1)\n",
    "# tvec_lemmatized_df.to_csv('../data/tvec_lemmatized_1500.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvec_lemmatized_3000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizing + Lemmatize\n",
    "# ct_vectorizer = ColumnTransformer([\n",
    "#                 ('selftext_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=3000), 'selftext'),\n",
    "#                 ('title_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=3000), 'title')\n",
    "#             ],\n",
    "#             remainder='drop',\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "\n",
    "# X_tvec = ct_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# tvec_lemmatized_df = pd.concat([pd.DataFrame(X_tvec.toarray(), columns=ct_vectorizer.get_feature_names_out()), y], axis=1)\n",
    "# tvec_lemmatized_df.to_csv('../data/tvec_lemmatized_3000.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvec_lemmatized_5000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizing + Lemmatize\n",
    "# ct_vectorizer = ColumnTransformer([\n",
    "#                 ('selftext_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=5000), 'selftext'),\n",
    "#                 ('title_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=5000), 'title')\n",
    "#             ],\n",
    "#             remainder='drop',\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "\n",
    "# X_tvec = ct_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# tvec_lemmatized_df = pd.concat([pd.DataFrame(X_tvec.toarray(), columns=ct_vectorizer.get_feature_names_out()), y], axis=1)\n",
    "# tvec_lemmatized_df.to_csv('../data/tvec_lemmatized_5000.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvec_lemmatized_10000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizing + Lemmatize\n",
    "# ct_vectorizer = ColumnTransformer([\n",
    "#                 ('selftext_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=10000), 'selftext'),\n",
    "#                 ('title_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=10000), 'title')\n",
    "#             ],\n",
    "#             remainder='drop',\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "\n",
    "# X_tvec = ct_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# tvec_lemmatized_df = pd.concat([pd.DataFrame(X_tvec.toarray(), columns=ct_vectorizer.get_feature_names_out()), y], axis=1)\n",
    "# tvec_lemmatized_df.to_csv('../data/tvec_lemmatized_10000.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvec_lemmatized_1000_bigram.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizing + Lemmatize\n",
    "# ct_vectorizer = ColumnTransformer([\n",
    "#                 ('selftext_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=1000, ngram_range=(1, 2)), 'selftext'),\n",
    "#                 ('title_vec', TfidfVectorizer(tokenizer=tokenize_lemmatize, max_features=1000, ngram_range=(1, 2)), 'title')\n",
    "#             ],\n",
    "#             remainder='drop',\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "\n",
    "# X_tvec = ct_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# tvec_lemmatized_df = pd.concat([pd.DataFrame(X_tvec.toarray(), columns=ct_vectorizer.get_feature_names_out()), y], axis=1)\n",
    "# tvec_lemmatized_df.to_csv('../data/tvec_lemmatized_1000_bigram.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
